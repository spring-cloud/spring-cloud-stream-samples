== What is this app?

This is an example of a Spring Cloud Stream processor using Kafka Streams support.

This is a demonstration of deserialization errors and DLQ in Kafka Streams binder.

The example is based on the word count application from the https://github.com/confluentinc/examples/blob/3.2.x/kafka-streams/src/main/java/io/confluent/examples/streams/WordCountLambdaExample.java[reference documentation].
It uses a single input and a single output.
In essence, the application receives text messages from an input topic and computes word occurrence counts in a configurable time window and report that in an output topic.
This sample uses lambda expressions and thus requires Java 8+.

==== Starting Kafka in a docker container

* Skip steps 1-3 if you already have a non-Docker Kafka environment.

1. Go to the docker directory in this repo and invoke the command `docker-compose up -d`.
2. Ensure that in the docker directory and then invoke the script `start-kafka-shell.sh`
3. cd $KAFKA_HOME
4. Start the console producer: +
Assuming that you are running kafka on a docker container on mac osx. Change the zookeeper IP address accordingly otherwise. +
`bin/kafka-console-producer.sh --broker-list 192.168.99.100:9092 --topic words`
5. Start the console consumer: +
Assuming that you are running kafka on a docker container on mac osx. Change the zookeeper IP address accordingly otherwise. +
`bin/kafka-console-consumer.sh --bootstrap-server 192.168.99.100:9092 --topic counts`

=== Running the app:

Go to the root of the repository and do: `./mvnw clean package`

`java -jar target/kstream-word-count-0.0.1-SNAPSHOT.jar`

* By default we use the docker container IP (mac osx specific) in the `application.yml` for Kafka broker and zookeeper.
Change it in `application.yml` (which requires a rebuild) or pass them as runtime arguments as below.

`spring.cloud.stream.kstream.binder.brokers=<Broker IP Address>` +
`spring.cloud.stream.kstream.binder.zkNodes=<Zookeeper IP Address>`

The default application.yml file demonstrates native decoding by Kafka.
The default value serializer is set to IntegerSerde and from the console send some ascii text data.
You will see that the messages erred on deserialization end up in the DLQ topic - words-count-dlq.

There is another yaml file provided (by-framework-decoding.yml).
Use that as application.yml to see when it works when the deserialization done by the framework.
In this case also, the messages on error appear in the DLQ topic.

Look in the console for what is doing the serialization/deserializtion.
You will see messages as below on the console:

"Native decoding is disabled for input. Inbound message conversion done by Spring Cloud Stream."

"Native encoding is disabled for counts. Outbound message conversion done by Spring Cloud Stream.

